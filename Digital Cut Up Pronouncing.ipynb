{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this final digital-cut up assignment, I wanted to create a free-verse rhyme with a spacy-generated text. However, I ran into some issues with Pincelate (couldn't load the model despite successfully importing the module), so I decided to stick with Pronouncing for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pincelate import Pincelate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"alice.txt\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing all the necessary modules, I decided to use Alice in Wonderland as my source text because adding in syllabic structure and pronounciation seemed like it would get quite confusing, and Alice has always been a good text to manipulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in list(doc) if w.is_alpha]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cycle through all of the words in the doc and store them in words variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_subtree(st):\n",
    "    return ''.join([w.text_with_ws for w in list(st)]).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the subtrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [flatten_subtree(word.subtree).replace(\"\\n\", \" \")\n",
    "            for word in doc if word.dep_ in ('nsubj', 'nsubjpass')]\n",
    "past_tense_verbs = [word.text for word in words if word.tag_ == 'VBD' and word.lemma_ != 'be']\n",
    "adjectives = [word.text for word in words if word.tag_.startswith('JJ')]\n",
    "nouns = [word.text for word in words if word.tag_.startswith('NN')]\n",
    "prep_phrases = [flatten_subtree(word.subtree).replace(\"\\n\", \" \")\n",
    "                for word in doc if word.dep_ == 'prep']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define syntactic units of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracery\n",
    "from tracery.modifiers import base_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I bit.'"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = {\n",
    "    \"origin\": [\n",
    "        \"#subject.capitalize# #predicate#.\",\n",
    "        \"#subject.capitalize# #predicate#.\",\n",
    "        \"#prepphrase.capitalize#, #subject# #predicate#.\"\n",
    "    ],\n",
    "    \"predicate\": [\n",
    "        \"#verb#\",\n",
    "        \"#verb# #nounphrase#\",\n",
    "        \"#verb# #prepphrase#\"\n",
    "    ],\n",
    "    \"nounphrase\": [\n",
    "        \"the #noun#\",\n",
    "        \"the #adj# #noun#\",\n",
    "        \"the #noun# #prepphrase#\",\n",
    "        \"the #noun# and the #noun#\",\n",
    "        \"#noun.a#\",\n",
    "        \"#adj.a# #noun#\",\n",
    "        \"the #noun# that #predicate#\"\n",
    "    ],\n",
    "    \"subject\": subjects,\n",
    "    \"verb\": past_tense_verbs,\n",
    "    \"noun\": nouns,\n",
    "    \"adj\": adjectives,\n",
    "    \"prepphrase\": prep_phrases\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "grammar.flatten(\"#origin#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the grammar structure (I used the grammar structure that was defined in the Tracery tutorial, since it seemed to be an exact replica of how English grammar works)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"Apoem.txt\", \"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the empty text file to store the output in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the tea, she had the exact pack. The jury all said an\n",
      "eager DAMAGES. I gave a little OUTSIDE. It declared of him.\n",
      "Of such a rule at processions, I had. Of-the-way, he went.\n",
      "Alice looked a print. Of pretending to be two people, you\n",
      "went. In a natural way, she minded. Him asked to herself.\n",
      "She made the kid In which. She said a much tears. On it, I\n",
      "said at a reasonable pace. For a minute or two, they\n",
      "fancied. Plates and dishes said the profits that found. YOU\n",
      "succeeded. With all her knowledge of history, it turned. The\n",
      "twelve jurors went an Alice. They hit of little cartwheels.\n",
      "Alice had a mouth. What marked at her. With both paragraphs\n",
      "1.E.1, I began without a grin. You left in a moment. He had.\n",
      "With the name 'W. RABBIT', they yawned. She cheered the\n",
      "paragraphs and the half. She Said with such sudden violence\n",
      "that Alice quite jumped. The March Hare fanned like a snout.\n",
      "They said a Queen. She puzzled by his face. Whose cause did\n",
      "a stiff soldiers. As, you tried. Some of the other birds\n",
      "tried the personal hurry. To her great disappointment it was\n",
      "empty, I had the hair in chorus. It jumped to. I repeated.\n",
      "The procession said the copying and the month. You went from\n",
      "the trees. She thought. --where went on the top of it. By\n",
      "the way, I went. Of expecting nothing but out-of-the-way\n",
      "things to happen, Alice said at you. I had the PURPOSE that\n",
      "had. I took. The Hatter said the little holder. About it,\n",
      "you went the butter. She thought. Of the Project Gutenberg-\n",
      "tm trademark, who made to trouble. With the strange\n",
      "creatures of her little sister's dream, I said. The\n",
      "adventures first ran all round the table. She thought a true\n",
      "comfort. At once, I said. It began of the place where you\n",
      "are located. Under its feet, Alice fancied. He recognised.\n",
      "Of thing, You mentioned the present thimble. With trying,\n",
      "you cheered the voice such as mouse-traps, and the moon, and\n",
      "memory, and muchness. The Queen sat about. The Duchess felt\n",
      "the same floor. He ran the License and the everybody. You\n",
      "cried. I had 'not in that ridiculous fashion. Like\n",
      "telescopes, you had OF THE POSSIBILITY OF SUCH DAMAGE. Of\n",
      "it, who waited the REMEDIES and the school. Alice hurried to\n",
      "the Dormouse. His scaly friend beat. Of it, that cheated the\n",
      "nothing and the March. Ferrets walked. She passed about\n",
      "something. The fact had. The unfortunate little Bill said a\n",
      "great head. On their slates, it remembered from. With a\n",
      "cart-horse, you drew with that. 1.B.  \"Project Gutenberg\n",
      "said in the United States. With, it looked the thing. Of the\n",
      "sense, who bit into the way of expecting nothing but out-of-\n",
      "the-way things to happen. What all about, it said. It began\n",
      "over the wig. It said to the end of his tail. She deserved a\n",
      "friends. The Hatter persisted after a few minutes. In her\n",
      "lessons in the schoolroom, she said out of his pocket. With\n",
      "their hands and feet, you whispered a pale concert. The King\n",
      "found all about. What about, Alice put the March and the\n",
      "minute. I reduced the delighted sea. On the song, which kept\n",
      "for fear of killing somebody. She had. It looked an Alice.\n",
      "It received to herself. I spoke the place of these cakes. I\n",
      "said. For the first minute or two, you replied. In a hoarse,\n",
      "feeble voice, the King looked. He lived the copyright. On\n",
      "the ground, her hair screamed the pocket. Of 'Hjckrrh, It\n",
      "went at the bottom of the sea. The Dormouse started. I said\n",
      "upon them. With the requirements of paragraphs 1.E.1 through\n",
      "1.E.7, the Mock Turtle fell in a melancholy tone.\n"
     ]
    }
   ],
   "source": [
    "from textwrap import fill\n",
    "output = \" \".join([grammar.flatten(\"#origin#\") for i in range(100)])\n",
    "poemproto = (fill(output,60))\n",
    "text_file.write(poemproto)\n",
    "print(poemproto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the new text based off of the grammar structure parameters, and write it into the empty text file. I set the range to 100 to make sure that I have enough content to work with in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_phones(w):\n",
    "    pfw = pronouncing.phones_for_word(w)\n",
    "    if len(pfw) == 0:\n",
    "        w = re.sub(\"[^a-z']\", \"\", w)\n",
    "        return \" \"\n",
    "    else:\n",
    "        return pfw[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the quick_phones function, since I could not import the Pincelate model, I modified it so that Pincelate wouldn't be called if the word's pronounciation is not found. Because I was working with Alice in Wonderland, I was pretty confident that there wouldn't be any sort of \"new\" words that would require Pincelate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kevindai/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnet_lines = [item for item in open(\"Apoem.txt\").read().split(\"\\n\") if len(item) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and read through the text file that we had stored previously of the tracery-generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing and the Cat. At once, Alice chanced underneath her\n",
      "work. Than what it might appear to others that what you were\n"
     ]
    }
   ],
   "source": [
    "picked = random.choice(sonnet_lines)\n",
    "picked_words = [w for w in nltk.word_tokenize(picked) if w[0].isalpha()]\n",
    "picked_rhyme = pronouncing.rhyming_part(quick_phones(picked_words[-1]))\n",
    "\n",
    "for line in random.sample(sonnet_lines, len(sonnet_lines)):\n",
    "    if picked == line:\n",
    "        continue\n",
    "    words = [w for w in nltk.word_tokenize(line) if w[0].isalpha()]\n",
    "    if len(words) == 0:\n",
    "        continue\n",
    "    if pronouncing.rhyming_part(quick_phones(words[-1])) == picked_rhyme:\n",
    "        print(picked)\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part took quite a long time to understand. From what I could gather from the tutorial, in order to create two consecutive lines that rhyme (or rhyming couplets), we must choose some line from the text, get the pronounciation of the last word in the line, and then check through every other line to find a sentence that contains a word at the end that rhymes with the initial sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "rhyming_part_to_idx = defaultdict(lambda: defaultdict(list))\n",
    "for i, line in enumerate(sonnet_lines):\n",
    "    words = [w for w in nltk.word_tokenize(line) if w[0].isalpha()]\n",
    "    if len(words) > 0:\n",
    "        last_few = \" \".join([quick_phones(w) for w in words[-3:]])\n",
    "        rhyming_part = pronouncing.rhyming_part(last_few)\n",
    "        rhyming_part_to_idx[rhyming_part][words[-1]].append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we had to check through every line to find the rhyme match, the tutorial also offered an alternative when working with larger corpuses. Although Alice in Wonderland isn't that large, I decided to try and follow this method in case I ended up working with a big corpus in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhyme_map = {k: v for k, v in rhyming_part_to_idx.items() if len(v) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canvas. Of short charges, she did the Alice round her head.\n",
      "You EDITION. The Mock Turtle in a deep, hollow tone: said\n",
      "Till now, Alice began in a very humble tone, going down on\n",
      "payments and credit card donations, you spoke the half. On\n",
      "ready thing. Alice, came the accordance that sat. It took\n",
      "She spoke. Except the King, the Queen, and Alice, it shook\n",
      "the short court. It had a sorrow. The jury all had without\n",
      "the ill Alice. This work gave the same Alice. Without\n",
      "the house of the March Hare. I drew of the leaves: '. That\n",
      "began. I did the shore. The others cried. I led just at\n",
      "permission, what turned a little Mouse. I said. Who flew.\n",
      "saw a free Project. I remarked of its mouth. In a few\n",
      "You gave the Gryphon at me. Without considering at all this\n",
      "that did as. With one finger, I said. Alice said UNDER THIS\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    rhyming_part = random.choice(list(rhyme_map.keys()))\n",
    "    a_set, b_set = random.sample(list(rhyme_map[rhyming_part].keys()), 2)\n",
    "    a_idx = random.choice(rhyme_map[rhyming_part][a_set])\n",
    "    b_idx = random.choice(rhyme_map[rhyming_part][b_set])\n",
    "    print(\"\\n\".join([sonnet_lines[a_idx], sonnet_lines[b_idx]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the output that I received. A bit strange since none of the sentences make sense at all, and I also forgot to remove the license summary in the txt file so that part blended in as well. However, the end of each couplet end up rhyming, which was what I was trying to experiment with. Although not entirely a flop, I do hope to fix the issue with Pincelate on my computer in order to generate actual poems with structure. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
